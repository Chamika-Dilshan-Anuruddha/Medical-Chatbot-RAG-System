{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd341a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a84abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\anuru\\\\Desktop\\\\MyPro\\\\Medical-Chatbot-RAG-System'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc9d45",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3169f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    original_data_path: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    data_ingestion_path: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_validation_path: Path\n",
    "    vectorstore_path: Path\n",
    "    embedding_model_name: str\n",
    "    chunk_size: int\n",
    "    chunk_overlap: int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    vectorstore_path: Path\n",
    "    model_name: str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f459a2",
   "metadata": {},
   "source": [
    "### Configuraiton Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08c9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MedicalChatbot.constants import *\n",
    "from MedicalChatbot.utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5510827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfiguraitonManager:\n",
    "    def __init__(self,config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self)->DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            data_path = Path(config.data_path),\n",
    "            original_data_path = Path(config.original_data_path)\n",
    "        )\n",
    "        return data_ingestion_config\n",
    "    \n",
    "    def get_data_validation_config(self)->DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        create_directories([config.root_dir])\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            data_path = Path(config.data_path),\n",
    "            data_ingestion_path = Path(config.data_ingestion_path),\n",
    "        )\n",
    "        return data_validation_config\n",
    "    \n",
    "\n",
    "    def get_data_transformation_config(self)->DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "        data_transformation_confg = DataTransformationConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            data_validation_path = Path(config.data_validation_path),\n",
    "            vectorstore_path = Path(config.vectorstore_path),\n",
    "            embedding_model_name = config.embedding_model_name,\n",
    "            chunk_size = self.params.CHUNK_SIZE,\n",
    "            chunk_overlap = self.params.CHUNK_OVERLAP\n",
    "        )\n",
    "        return data_transformation_confg\n",
    "    \n",
    "    def get_model_trainer_config(self)->ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        create_directories([config.root_dir])\n",
    "        model_trainer_cofig = ModelTrainerConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            vectorstore_path = Path(config.vectorstore_path),\n",
    "            model_name = config.model_name\n",
    "        )\n",
    "        return model_trainer_cofig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb91619",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47689f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from MedicalChatbot.logging import logger\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e91589b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self,config:DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_data(self):\n",
    "        print(\"Data downloaded successfully\")\n",
    "        logger.info(\"Data downloaded successfully...\")\n",
    "    \n",
    "    def copy_data(self):\n",
    "        source_dirpath  = self.config.original_data_path\n",
    "        destination_dirpath = self.config.data_path\n",
    "        create_directories([destination_dirpath])\n",
    "        files = os.listdir(source_dirpath)\n",
    "        for file in files:\n",
    "            file_type = file.split(\".\")[-1].lower()\n",
    "            if file_type == \"pdf\":\n",
    "                shutil.copy(os.path.join(source_dirpath,file),destination_dirpath)\n",
    "        logger.info(\"Data copied successfully...\")\n",
    "\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self,config:DataValidationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def data_validation(self):\n",
    "        source_dirpath = self.config.data_ingestion_path\n",
    "        destination_dirpath = self.config.data_path\n",
    "        create_directories([destination_dirpath])\n",
    "        files = os.listdir(source_dirpath)\n",
    "        for file in files:\n",
    "            shutil.copy(os.path.join(source_dirpath,file),destination_dirpath)\n",
    "        logger.info(\"Data validation completed...\")\n",
    "\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def _get_embedding_model(self):\n",
    "        embedding = HuggingFaceEmbeddings(model_name = self.config.embedding_model_name)\n",
    "        logger.info(\"Embedding model retrieved...\")\n",
    "        return embedding\n",
    "    \n",
    "    def _get_inmemory_vectorstore(self,embedding):   \n",
    "        vector_store = InMemoryVectorStore(embedding)\n",
    "        logger.info(\"Vector store retrieved...\")\n",
    "        return vector_store\n",
    "    \n",
    "    def load_pdf_documents(self):\n",
    "        loader = PyPDFDirectoryLoader(self.config.data_validation_path)\n",
    "        docs = loader.load()\n",
    "        logger.info(\"Documents are loaded...\")\n",
    "        return docs\n",
    "    \n",
    "    def split_pdf_loaded_documents(self,docs):\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.config.chunk_size,\n",
    "            chunk_overlap=self.config.chunk_overlap,\n",
    "            add_start_index=True\n",
    "        )\n",
    "        all_splits = text_splitter.split_documents(docs)\n",
    "        logger.info(\"PDF loaded docs are splitted...\")\n",
    "        return all_splits\n",
    "    \n",
    "    def create_and_save_vectorstore(self,all_splits):\n",
    "        embeddings = self._get_embedding_model()\n",
    "        vector_store = self._get_inmemory_vectorstore(embeddings)\n",
    "        document_ids = vector_store.add_documents(all_splits)\n",
    "        vector_store.dump(self.config.vectorstore_path)\n",
    "        logger.info(\"Vector store created and stored...\")\n",
    "        return vector_store\n",
    "\n",
    "    def get_saved_vectorsote(self):\n",
    "        vector_store = InMemoryVectorStore.load(self.config.vectorstore_path, self._get_embedding_model())\n",
    "        logger.info(\"Vector store retrieved...\")\n",
    "        return vector_store\n",
    "    \n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self,config:ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.data_transformation = self._get_data_transformation_object()\n",
    "        self.model = self._get_model()\n",
    "\n",
    "    def _get_model(self):\n",
    "        model = init_chat_model(self.config.model_name)\n",
    "        logger.info(\"LLM model is retrieved...\")\n",
    "        return model\n",
    "    \n",
    "    def _get_data_transformation_object(self):\n",
    "        config_manager = ConfiguraitonManager()\n",
    "        data_transformation_obj = DataTransformation(config_manager.get_data_transformation_config())\n",
    "        return data_transformation_obj\n",
    "\n",
    "\n",
    "    def generate_system_message(self,user_query):\n",
    "        vector_store = self.data_transformation.get_saved_vectorsote()\n",
    "        retrieved_docs = vector_store.similarity_search(user_query)\n",
    "        docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "        system_message = (\n",
    "            \"Yor are a helpful assistant. Use the following context in your response:\"\n",
    "            f\"\\n\\n{docs_content}\"\n",
    "        )\n",
    "        logger.info(\"System prompt is generated...\")\n",
    "        return system_message\n",
    "    \n",
    "\n",
    "    def get_agent(self):\n",
    "        agent = create_agent(self.model)\n",
    "        logger.info(\"Agent is created...\")\n",
    "        return agent\n",
    "    \n",
    "    \n",
    "    def get_result(self,query,agent):\n",
    "        resulst = agent.invoke({\"messages\": [\n",
    "            {\"role\":\"system\", \"content\":self.generate_system_message(query)},\n",
    "            {\"role\":\"user\", \"content\":query}\n",
    "        ]})\n",
    "\n",
    "        client_result = resulst[\"messages\"][-1].content\n",
    "        return client_result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7a4e1",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d949d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from MedicalChatbot.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac04a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-10 11:17:17,866: INFO: __init__: Directory: artifacts is created:]\n",
      "[2026-02-10 11:17:17,869: INFO: __init__: Directory: artifacts/data_ingestion is created:]\n",
      "[2026-02-10 11:17:17,871: INFO: __init__: Directory: artifacts\\data_ingestion\\data is created:]\n",
      "[2026-02-10 11:17:17,887: INFO: 1233119677: Data copied successfully...:]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfiguraitonManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(data_ingestion_config)\n",
    "    data_ingestion.copy_data()\n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bfeaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-10 11:17:17,915: INFO: __init__: Directory: artifacts is created:]\n",
      "[2026-02-10 11:17:17,919: INFO: __init__: Directory: artifacts/data_validation is created:]\n",
      "[2026-02-10 11:17:17,922: INFO: __init__: Directory: artifacts\\data_validation\\train is created:]\n",
      "[2026-02-10 11:17:17,984: INFO: 1233119677: Data validation completed...:]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfiguraitonManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValidation(data_validation_config)\n",
    "    data_validation.data_validation()\n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1791b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-10 11:17:18,008: INFO: __init__: Directory: artifacts is created:]\n",
      "[2026-02-10 11:17:18,013: INFO: __init__: Directory: artifacts/data_transformation is created:]\n",
      "[2026-02-10 11:17:40,195: INFO: 1233119677: Documents are loaded...:]\n",
      "[2026-02-10 11:17:40,297: INFO: 1233119677: PDF loaded docs are splitted...:]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfiguraitonManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    docs = data_transformation.load_pdf_documents()\n",
    "    all_splits = data_transformation.split_pdf_loaded_documents(docs)\n",
    "    #vector_store = data_transformation.create_and_save_vectorstore(all_splits)\n",
    "    #vector_store = data_transformation.get_saved_vectorsote()\n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2b02d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-10 11:32:46,533: INFO: __init__: Directory: artifacts is created:]\n",
      "[2026-02-10 11:32:46,534: INFO: __init__: Directory: artifacts/model_trainer is created:]\n",
      "[2026-02-10 11:32:46,541: INFO: __init__: Directory: artifacts is created:]\n",
      "[2026-02-10 11:32:46,543: INFO: __init__: Directory: artifacts/data_transformation is created:]\n",
      "[2026-02-10 11:32:47,018: INFO: 2818467830: LLM model is retrieved...:]\n",
      "[2026-02-10 11:32:47,021: INFO: 2818467830: Agent is created...:]\n",
      "[2026-02-10 11:32:47,023: INFO: SentenceTransformer: Use pytorch device_name: cpu:]\n",
      "[2026-02-10 11:32:47,025: INFO: SentenceTransformer: Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2:]\n",
      "[2026-02-10 11:32:47,717: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:47,921: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/modules.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:48,328: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:48,439: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/config_sentence_transformers.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:48,739: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:48,842: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/config_sentence_transformers.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:49,148: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:49,252: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/README.md \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:49,560: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:49,661: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/modules.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:49,961: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:50,084: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/sentence_bert_config.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:50,378: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\":]\n",
      "[2026-02-10 11:32:50,693: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:50,800: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/config.json \"HTTP/1.1 200 OK\":]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baf8f623b354acf8d12535763722d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mMPNetModel LOAD REPORT\u001b[0m from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-10 11:32:51,571: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:51,710: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/config.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:52,007: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:52,137: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/tokenizer_config.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:52,532: INFO: _client: HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-mpnet-base-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\":]\n",
      "[2026-02-10 11:32:52,842: INFO: _client: HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-mpnet-base-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:53,252: INFO: _client: HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\":]\n",
      "[2026-02-10 11:32:53,363: INFO: _client: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:53,677: INFO: _client: HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-mpnet-base-v2 \"HTTP/1.1 200 OK\":]\n",
      "[2026-02-10 11:32:53,683: INFO: 2818467830: Embedding model retrieved...:]\n",
      "[2026-02-10 11:32:55,031: INFO: 2818467830: Vector store retrieved...:]\n",
      "[2026-02-10 11:32:55,271: INFO: 2818467830: System prompt is generated...:]\n",
      "[2026-02-10 11:32:55,307: INFO: models: AFC is enabled with max remote calls: 10.:]\n",
      "[2026-02-10 11:32:56,608: INFO: _client: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\":]\n",
      "IBD stands for **Inflammatory bowel disease**. It is a condition in which the lining of the intestine becomes inflamed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfiguraitonManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(model_trainer_config)\n",
    "    agent = model_trainer.get_agent()\n",
    "\n",
    "    user_query = \"What is IBD ?\"\n",
    "    result = model_trainer.get_result(user_query,agent)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fc7f24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langgraph.graph.state.CompiledStateGraph"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
