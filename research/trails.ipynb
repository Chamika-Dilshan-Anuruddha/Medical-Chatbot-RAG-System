{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c17a11",
   "metadata": {},
   "source": [
    "https://docs.langchain.com/oss/python/langchain/rag#huggingface-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c746cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e215f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec70e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "c:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/Phi-3-mini-4k-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuggingface\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:452\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    444\u001b[39m     warnings.warn(\n\u001b[32m    445\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    447\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    448\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    449\u001b[39m     )\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    458\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:476\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m model, model_provider = _parse_model(model, model_provider)\n\u001b[32m    475\u001b[39m creator_func = _get_chat_model_creator(model_provider)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreator_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:58\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(cls, model, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[BaseChatModel], **kwargs: Any) -> BaseChatModel:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# TODO: replace with operator.call when lower bounding to Python 3.11\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**kwargs)\n\u001b[32m     38\u001b[39m _SUPPORTED_PROVIDERS: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, Callable[..., BaseChatModel]]] = {\n\u001b[32m     39\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manthropic\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_anthropic\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatAnthropic\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     40\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mazure_ai\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_azure_ai.chat_models\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAzureAIChatCompletionsModel\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mazure_openai\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_openai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAzureChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     42\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbedrock\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_aws\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatBedrock\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     43\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbedrock_converse\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_aws\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatBedrockConverse\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     44\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcohere\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_cohere\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatCohere\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdeepseek\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_deepseek\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatDeepSeek\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfireworks\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_fireworks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatFireworks\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     47\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgoogle_anthropic_vertex\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     48\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlangchain_google_vertexai.model_garden\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     49\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatAnthropicVertex\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m         _call,\n\u001b[32m     51\u001b[39m     ),\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgoogle_genai\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_google_genai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatGoogleGenerativeAI\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     53\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgoogle_vertexai\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_google_vertexai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatVertexAI\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     54\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_groq\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatGroq\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     55\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhuggingface\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     56\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlangchain_huggingface\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     57\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatHuggingFace\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, model, **kwargs: \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_model_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     59\u001b[39m     ),\n\u001b[32m     60\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mibm\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     61\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlangchain_ibm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatWatsonx\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     63\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, model, **kwargs: \u001b[38;5;28mcls\u001b[39m(model_id=model, **kwargs),\n\u001b[32m     64\u001b[39m     ),\n\u001b[32m     65\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmistralai\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_mistralai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatMistralAI\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     66\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnvidia\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_nvidia_ai_endpoints\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatNVIDIA\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mollama\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_ollama\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatOllama\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     68\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_openai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     69\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mperplexity\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_perplexity\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatPerplexity\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     70\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtogether\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_together\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatTogether\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     71\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mupstage\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_upstage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatUpstage\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     72\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mxai\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mlangchain_xai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatXAI\u001b[39m\u001b[33m\"\u001b[39m, _call),\n\u001b[32m     73\u001b[39m }\n\u001b[32m     74\u001b[39m \u001b[33;03m\"\"\"Registry mapping provider names to their import configuration.\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m \u001b[33;03mEach entry maps a provider key to a tuple of:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m \u001b[33;03m- `creator_func`: A callable that instantiates the class with provided kwargs.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_import_module\u001b[39m(module: \u001b[38;5;28mstr\u001b[39m, class_name: \u001b[38;5;28mstr\u001b[39m) -> ModuleType:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:676\u001b[39m, in \u001b[36mChatHuggingFace.from_model_id\u001b[39m\u001b[34m(cls, model_id, task, backend, **kwargs)\u001b[39m\n\u001b[32m    673\u001b[39m     pipeline_specific_kwargs[\u001b[33m\"\u001b[39m\u001b[33mpipeline_kwargs\u001b[39m\u001b[33m\"\u001b[39m].update(generation_params)\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# Create the HuggingFacePipeline\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m     llm = \u001b[43mHuggingFacePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_model_id\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpipeline_specific_kwargs\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend == \u001b[33m\"\u001b[39m\u001b[33mendpoint\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhuggingface_endpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    681\u001b[39m         HuggingFaceEndpoint,\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\langchain_huggingface\\llms\\huggingface_pipeline.py:218\u001b[39m, in \u001b[36mHuggingFacePipeline.from_model_id\u001b[39m\u001b[34m(cls, model_id, task, backend, device, device_map, model_kwargs, pipeline_kwargs, batch_size, **kwargs)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    212\u001b[39m     model_cls = (\n\u001b[32m    213\u001b[39m         AutoModelForCausalLM\n\u001b[32m    214\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m task == \u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m AutoModelForSeq2SeqLM\n\u001b[32m    216\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m model = \u001b[43mmodel_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(model_id, **_model_kwargs)\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model.config.pad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1893\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   1891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m1893\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1879\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   1876\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   1878\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m1879\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "model = init_chat_model(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    model_provider=\"huggingface\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m embeddings = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers/all-mpnet-base-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:68\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**kwargs)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     70\u001b[39m     msg = (\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfit_mixin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FitMixin\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData, generate_model_card\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     38\u001b[39m     cross_encoder_init_args_decorator,\n\u001b[32m     39\u001b[39m     cross_encoder_predict_rank_args_decorator,\n\u001b[32m     40\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\fit_mixin.py:24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mSentenceEvaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mSentenceTransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchSamplers\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_datasets_available\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfit_mixin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FitMixin\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pooling, Transformer\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpeft_mixin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantize_embeddings\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     batch_to_device,\n\u001b[32m     49\u001b[39m     get_device_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     truncate_embeddings,\n\u001b[32m     56\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\sentence_transformers\\peft_mixin.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wraps\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin \u001b[38;5;28;01mas\u001b[39;00m PeftAdapterMixinTransformers\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpeft_wrapper\u001b[39m(func):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrapper to call the method on the auto_model with a check for PEFT compatibility.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\transformers\\integrations\\peft.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m replace\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Literal, Optional\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconversion_mapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     _MODEL_TO_CONVERSION_PATTERN,\n\u001b[32m     24\u001b[39m     get_checkpoint_conversion_mapping,\n\u001b[32m     25\u001b[39m     get_model_conversion_mapping,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore_model_loading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     Concatenate,\n\u001b[32m     29\u001b[39m     ConversionOps,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     WeightRenaming,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     36\u001b[39m     CONFIG_NAME,\n\u001b[32m     37\u001b[39m     cached_file,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     logging,\n\u001b[32m     45\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\transformers\\conversion_mapping.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore_model_loading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     Chunk,\n\u001b[32m     22\u001b[39m     Concatenate,\n\u001b[32m     23\u001b[39m     ErnieFuseAndSplitTextVisionExperts,\n\u001b[32m     24\u001b[39m     Force16BytesAlignment,\n\u001b[32m     25\u001b[39m     MergeModulelist,\n\u001b[32m     26\u001b[39m     Transpose,\n\u001b[32m     27\u001b[39m     WeightConverter,\n\u001b[32m     28\u001b[39m     WeightRenaming,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_torch_available\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\transformers\\core_model_loading.py:35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_device, offload_weight\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_parallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALL_PARALLEL_STYLES\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_env_variable_true, logging\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloading_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoadStateDictInfo\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\MyProjects\\Medical-Chatbot-RAG-System\\venv\\Lib\\site-packages\\transformers\\integrations\\tensor_parallel.py:450\u001b[39m\n\u001b[32m    426\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.chunk(x, world_size, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# Distributed Communication Primitives\u001b[39;00m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    446\u001b[39m \u001b[38;5;66;03m#   └────────────────────┴─────────────────────┴─────────────────────┘\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# ===================\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_AllReduceBackward\u001b[39;00m(\u001b[43mtorch\u001b[49m.autograd.Function):\n\u001b[32m    451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Identity forward, all-reduce backward. Used before colwise layers (f in Megatron).\"\"\"\u001b[39;00m\n\u001b[32m    453\u001b[39m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(ctx, x, device_mesh):\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b469e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\",\"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\"),\n",
    "    bs_kwargs={\"parse_only\":bs4_strainer}\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents\")\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request:ModelRequest)->str:\n",
    "    last_query = request.state[\"message\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    system_message = (\n",
    "        \"Yor are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04077cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition?\"\n",
    "for setp in agent.stream(\n",
    "    {\"message\": [{\"role\":\"user\", \"content\":query}]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    setp[\"message\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
